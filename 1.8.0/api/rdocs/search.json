[{"path":"/articles/apache-sedona.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Introduction to Apache Sedona for R","text":"apache.sedona sparklyr-based R interface Apache Sedona. presents Apache Sedona offer idiomatic frameworks constructs R (e.g., one can build spatial Spark SQL queries using Sedona UDFs conjunction wide range dplyr expressions), hence making Apache Sedona highly friendly R users. Generally speaking, working Apache Sedona, one choose following two modes: Manipulating Sedona Spatial Resilient Distributed Datasets spatial-RDD-related routines Querying geometric columns within Spatial DataFrames Sedona spatial UDFs former option enables fine-grained control low-level implementation details (e.g., index build spatial queries, data structure use spatial partitioning, etc), latter simpler leads straightforward integration dplyr, sparklyr, sparklyr extensions (e.g., one can build ML feature extractors Sedona UDFs connect ML pipelines using ml_*() family functions sparklyr, hence creating ML workflows capable understanding spatial data). data spatial RDDs can imported Spark DataFrames geometry columns vice versa, one can switch abovementioned two modes fairly easily. moment apache.sedona consists following components: Reading/writing spatial data WKT, WKB, GeoJSON formats Shapefile reader Spatial partition, index, join, KNN query, range query operations Visualization routines See SQL APIs list available UDFs Functions importing data spatial RDDs Spark DataFrames vice versa","code":""},{"path":"/articles/apache-sedona.html","id":"connect-to-spark","dir":"Articles","previous_headings":"","what":"Connect to Spark","title":"Introduction to Apache Sedona for R","text":"ensure Sedona serialization routines, UDTs, UDFs properly registered creating Spark session, one simply needs attach apache.sedona instantiating Spark connection. apache.sedona take care rest. example, create Sedona-capable Spark connection YARN client mode, create Sedona-capable Spark connection Apache Spark instance running locally. sparklyr, one can easily inspect Spark connection object sanity-check properly initialized Sedona-related dependencies, e.g., information connecting Spark sparklyr, see https://therinspark.com/connections.html ?sparklyr::spark_connect. Also see Initiate Spark Context Initiate Spark Session minimum recommended dependencies Apache Sedona.","code":"library(sparklyr) library(apache.sedona)  spark_home <- \"/usr/lib/spark\"  # NOTE: replace this with your $SPARK_HOME directory sc <- spark_connect(master = \"yarn\", spark_home = spark_home) library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"local\") print(sc$extensions$packages) spark_session(sc) %>%   invoke(\"%>%\", list(\"conf\"), list(\"get\", \"spark.kryo.registrator\")) %>%   print()"},{"path":"/articles/apache-sedona.html","id":"dplyr-workflows","dir":"Articles","previous_headings":"","what":"dplyr workflows","title":"Introduction to Apache Sedona for R","text":"apache.sedona extends sparklyr integrates dplyr workflows. See sparklyr cheatsheet","code":"library(dplyr)"},{"path":[]},{"path":"/articles/apache-sedona.html","id":"copying-from-r","dir":"Articles","previous_headings":"dplyr workflows > Loading data","what":"Copying from R","title":"Introduction to Apache Sedona for R","text":"Data loaded R can copied Spark using copy_to. Columns containing spatial information can converted geometry type Spark DataFrames (GeometryUDT) Spark SQL functions ST_GeomFromText ST_GeomFromText, see Vector constructors Raster input output. automatic translation sf objects provided, need converted text (binary) format copying spark.","code":"data <- readr::read_csv(here::here(\"../spark/common/src/test/resources/arealm.csv\"), col_names = FALSE, show_col_types = FALSE) data %>% glimpse()  data_tbl <- copy_to(sc, data)  data_tbl  data_tbl %>%   transmute(geometry = st_geomfromtext(X1)) %>%   sdf_schema() data <- sf::st_read(here::here(\"../spark/common/src/test/resources/testPolygon.json\"))  data %>% glimpse()  data_tbl <-   copy_to(     sc,     data %>%     mutate(geometry_wkb = geometry %>% sf::st_as_text()) %>%     sf::st_drop_geometry(),   name = \"data\",   overwrite = TRUE )  data_tbl %>%   transmute(geometry = st_geomfromtext(geometry_wkb)) %>%   sdf_schema()"},{"path":"/articles/apache-sedona.html","id":"loading-directly-in-spark","dir":"Articles","previous_headings":"dplyr workflows > Loading data","what":"Loading directly in Spark","title":"Introduction to Apache Sedona for R","text":"Loading data R copying Spark likely optimal method prepare data analysis; loading data directly Spark often best.spark_read_* functions made purpose (extend spark_read_* functions sparklyr).","code":"data_tbl <- spark_read_geojson(sc, path = here::here(\"../spark/common/src/test/resources/testPolygon.json\"), name = \"data\")  data_tbl %>%   glimpse()  data_tbl %>%   # select(geometry) %>%   sdf_schema() %>%   lobstr::tree()"},{"path":"/articles/apache-sedona.html","id":"manipulating","dir":"Articles","previous_headings":"dplyr workflows","what":"Manipulating","title":"Introduction to Apache Sedona for R","text":"dbplyr interface transparently translates dbplyr workflows SQL, gives access Apache Sedona SQL functions: Vector functions Vector predicates Vector aggregate functions Raster operators Results collected back R collect. Geometries need converted serializable (text binary) format collect called:","code":"## ! ST_transform uses lon/lat order since v1.5.0. Before, it used lat/lon order. data_tbl %>%   mutate(     ALAND = ALAND %>% as.numeric(),     AWATER = AWATER %>% as.numeric(),     area = ALAND + AWATER,     geometry_proj = st_transform(geometry, \"epsg:4326\", \"epsg:5070\", TRUE),     area_geom = st_area(geometry_proj)     ) %>%   select(STATEFP, COUNTYFP, area, area_geom) %>%   head() %>%   collect() ## Setting the CRS in R post-collect data_tbl %>%   mutate(     area = st_area(st_transform(geometry, \"epsg:4326\", \"epsg:5070\", TRUE)),     geometry_wkb = geometry %>% st_asBinary()     ) %>%   select(COUNTYFP, geometry_wkb) %>%   head() %>%   collect() %>%   sf::st_as_sf(crs = 4326) ## Setting the CRS in Spark (and using EWKT to keep it) data_tbl %>%   mutate(     area = st_area(st_transform(geometry, \"epsg:4326\", \"epsg:5070\", TRUE)),     geometry_ewkt = geometry %>% st_setsrid(4326) %>% st_asewkt()     ) %>%   select(COUNTYFP, geometry_ewkt) %>%   head() %>%   collect() %>%   sf::st_as_sf(wkt = \"geometry_ewkt\")"},{"path":"/articles/apache-sedona.html","id":"writing","dir":"Articles","previous_headings":"dplyr workflows","what":"Writing","title":"Introduction to Apache Sedona for R","text":"Collected results can saved R. many cases efficient write results directly Spark. spark_write_* (see docs) functions made purpose (extend spark_write_* functions sparklyr). output can partitioned columns present data:","code":"dest_file <- tempfile() ## Destination folder data_tbl %>%   filter(str_sub(COUNTYFP, 1, 2) == \"00\") %>%   spark_write_geoparquet(path = dest_file)  dest_file %>% dir(recursive = TRUE) dest_file <- tempfile()  ## Destination folder data_tbl %>%   filter(str_sub(COUNTYFP, 1, 2) == \"00\") %>%   spark_write_geoparquet(path = dest_file, partition_by = \"COUNTYFP\")  dest_file %>% dir(recursive = TRUE)"},{"path":"/articles/apache-sedona.html","id":"spark-dataframes","dir":"Articles","previous_headings":"dplyr workflows","what":"Spark DataFrames","title":"Introduction to Apache Sedona for R","text":"Spark DataFrames provide higher level API RDDs, can used SQL queries. sparklyr apache.sedona automatically wrap Spark DataFrames dplyr tbls work dplyr workflows. can get underlying Spark DataFrame (SDF) sparklyr::spark_dataframe, used example spakrlyr::invoke call SDF methods within Spark.","code":"data_tbl %>% class() sdf <- data_tbl %>% spark_dataframe() sdf"},{"path":[]},{"path":"/articles/apache-sedona.html","id":"what-are-spatialrdds","dir":"Articles","previous_headings":"RDD workflows","what":"What are SpatialRDDs?","title":"Introduction to Apache Sedona for R","text":"SpatialRDDs basic building blocks distributed spatial data Apache Sedona. SpatialRDD can partitioned indexed using well-known spatial data structures facilitate range queries, KNN queries, low-level operations. One can also export records SpatialRDDs regular Spark DataFrames, making accessible Spark SQL dplyr interface sparklyr.","code":""},{"path":"/articles/apache-sedona.html","id":"creating-a-spatialrdd","dir":"Articles","previous_headings":"RDD workflows","what":"Creating a SpatialRDD","title":"Introduction to Apache Sedona for R","text":"NOTE: section largely based Spatial RDD Scala tutorial, except examples written R instead Scala reflect usages apache.sedona. Currently SpatialRDDs can created apache.sedona reading file supported geospatial format (sedona_read_* functions), extracting data Spark SQL query. example, following code import data arealm-small.csv SpatialRDD: Records example arealm-small.csv file look like following: one can see , record comma-separated consists 2-dimensional coordinate starting 2nd column ending 3rd column. columns contain non-spatial attributes. column indexes 0-based, need specify first_spatial_col_index = 1 example ensure record parsed correctly. addition formats CSV TSV, currently apache.sedona also supports reading files WKT (Well-Known Text), WKB (Well-Known Binary), Shapefile GeoJSON formats. See sedona_read_wkt() details.","code":"pt_rdd <- sedona_read_dsv_to_typed_rdd(   sc,   location = here::here(\"../spark/common/src/test/resources/arealm.csv\"),   delimiter = \",\",   type = \"point\",   first_spatial_col_index = 1,   has_non_spatial_attrs = TRUE ) testattribute0,-88.331492,32.324142,testattribute1,testattribute2 testattribute0,-88.175933,32.360763,testattribute1,testattribute2 testattribute0,-88.388954,32.357073,testattribute1,testattribute2"},{"path":"/articles/apache-sedona.html","id":"conversion-to-and-from-spatialrdd","dir":"Articles","previous_headings":"RDD workflows","what":"Conversion to and from SpatialRDD","title":"Introduction to Apache Sedona for R","text":"One can also run to_spatial_rdd() extract SpatialRDD Spark SQL query, e.g. query extract spatial column named \"geom\" Sedona spatial SQL query store SpatialRDD object. SpatialRDD can converted Spark DataFrame sdf_register (generic method sparklyr).","code":"library(dplyr)  sdf <- tbl(   sc,   sql(\"SELECT ST_GeomFromText('POINT(-71.064544 42.28787)') AS `geom`, \\\"point\\\" AS `type`\") )  spatial_rdd <- sdf %>% to_spatial_rdd(spatial_col = \"geom\") spatial_rdd spatial_sdf <- spatial_rdd %>% sdf_register(name = \"my_table\") spatial_sdf"},{"path":"/articles/apache-sedona.html","id":"visualization","dir":"Articles","previous_headings":"","what":"Visualization","title":"Introduction to Apache Sedona for R","text":"important part apache.sedona collection R interfaces Sedona visualization routines. example, following essentially R equivalent example Scala. create scatter plot, overlay top choropleth map, shown :  See ?apache.sedona::sedona_render_scatter_plot, ?apache.sedona::sedona_render_heatmap, ?apache.sedona::sedona_render_choropleth_map details visualization-related R interfaces currently implemented apache.sedona.","code":"resolution_x <- 1000 resolution_y <- 600 boundary <- c(-126.790180, -64.630926, 24.863836, 50.000)  pt_rdd <- sedona_read_dsv_to_typed_rdd(   sc,   location = here::here(\"../spark/common/src/test/resources/arealm.csv\"),   type = \"point\" ) polygon_rdd <- sedona_read_dsv_to_typed_rdd(   sc,   location = here::here(\"../spark/common/src/test/resources/primaryroads-polygon.csv\"),   type = \"polygon\" ) pair_rdd <- sedona_spatial_join_count_by_key(   pt_rdd,   polygon_rdd,   join_type = \"intersect\" )  overlay <- sedona_render_scatter_plot(   polygon_rdd,   resolution_x,   resolution_y,   output_location = tempfile(\"scatter-plot-\"),   boundary = boundary,   base_color = c(255, 0, 0),   browse = FALSE )  sedona_render_choropleth_map(   pair_rdd,   resolution_x,   resolution_y,   output_location = \"./choropleth-map\",   boundary = boundary,   overlay = overlay,   # vary the green color channel according to relative magnitudes of data points so   # that the resulting map will show light blue, light purple, and light gray pixels   color_of_variation = \"green\",   base_color = c(225, 225, 255) )"},{"path":"/articles/apache-sedona.html","id":"advanced-parameters","dir":"Articles","previous_headings":"","what":"Advanced parameters","title":"Introduction to Apache Sedona for R","text":"Various advanced parameters can set Apache Sedona, see parameters Currently working sparklyr config: Check (Still true) change runtime:","code":"config <- spark_config() config[[\"sedona.global.index\"]] <- FALSE  sc <- spark_connect(master = \"local\", config = config) invoke_new(sc, \"org.apache.sedona.core.utils.SedonaConf\", invoke(spark_session(sc), \"conf\")) spark_session(sc) %>%   invoke(\"conf\") %>%   invoke(\"set\", \"sedona.global.index\", \"false\")  invoke_new(sc, \"org.apache.sedona.core.utils.SedonaConf\", invoke(spark_session(sc), \"conf\")) invoke_new(sc, \"org.apache.sedona.core.utils.SedonaConf\", invoke(spark_session(sc), \"conf\"))"},{"path":[]},{"path":"/articles/raster.html","id":"read","dir":"Articles","previous_headings":"Using the RasterUDT","what":"Read","title":"Using raster data in Apache Sedona for R","text":"Raster data GeoTiff ArcInfo Grid format can loaded directly Spark using sparklyr::spark_read_binary Sedona constructors RS_FromGeoTiff RS_FromArcInfoAsciiGrid. data loaded, raster functions available dplyr workflows: Raster operators Raster input output Functions taking raster: Raster arguments meant used data loaded reader, RS_Value, RS_Values, RS_Envelope. Functions taking Band: Array[Double] arguments work data loaded using Sedona Geotiff DataFrame loader (see ). example, getting number bands: getting values envelope: getting values specific points:","code":"library(dplyr) library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"local\")  data_tbl <- spark_read_binary(sc, dir = here::here(\"/../spark/common/src/test/resources/raster/\"), name = \"data\")  raster <-   data_tbl %>%   mutate(raster = RS_FromGeoTiff(content))  raster  raster %>% sdf_schema() raster %>%   mutate(     nbands = RS_NumBands(raster)   ) %>%   select(path, nbands) %>%   collect() %>%   mutate(path = path %>% basename()) raster %>%   mutate(     env = RS_Envelope(raster) %>% st_astext()   ) %>%   select(path, env) %>%   collect() %>%   mutate(path = path %>% basename()) raster %>%   mutate(     val = RS_Value(raster, ST_Point(-13077301.685, 4002565.802))   ) %>%   select(path, val) %>%   collect() %>%   mutate(path = path %>% basename())"},{"path":"/articles/raster.html","id":"write","dir":"Articles","previous_headings":"Using the RasterUDT","what":"Write","title":"Using raster data in Apache Sedona for R","text":"write Sedona Raster DataFrame raster files, need (1) first convert Raster DataFrame binary DataFrame using RS_AsXXX functions (2) write binary DataFrame raster files using Sedona’s built-raster data source. write Sedona binary DataFrame external storage using Sedona’s built-raster data source, use spark_write_raster function: Available options see Raster writer: rasterField: binary column saved (one takes column default, otherwise specify) fileExtension: .tiff default, also accepts .png, .jpeg, .asc pathField: used column name indicates paths raster file, otherwise random UUIDs generated.","code":"dest_file <- tempfile() raster %>%   mutate(content = RS_AsGeoTiff(raster)) %>%   spark_write_raster(path = dest_file)  dir(dest_file, recursive = TRUE) dest_file <- tempfile() raster %>%   mutate(content = RS_AsArcGrid(raster)) %>%   spark_write_raster(path = dest_file,                      options = list(\"rasterField\" = \"content\",                                     \"fileExtension\" = \".asc\",                                     \"pathField\" = \"path\"                      ))  dir(dest_file, recursive = TRUE)"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Apache Sedona. Author, maintainer. Jia Yu. Contributor, copyright holder. Yitao Li. Author, copyright holder. Apache Software Foundation. Copyright holder. RStudio. Copyright holder.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Apache Sedona, Li Y (2026). apache.sedona: R Interface Apache Sedona. R package version 1.8.0, https://github.com/apache/sedona/.","code":"@Manual{,   title = {apache.sedona: R Interface for Apache Sedona},   author = {{Apache Sedona} and Yitao Li},   year = {2026},   note = {R package version 1.8.0},   url = {https://github.com/apache/sedona/}, }"},{"path":"/index.html","id":"apachesedona-","dir":"","previous_headings":"","what":"R Interface for Apache Sedona","title":"R Interface for Apache Sedona","text":"Apache Sedona cluster computing system processing large-scale spatial data. Sedona extends existing cluster computing systems, Apache Spark Apache Flink, set ---box distributed Spatial Datasets Spatial SQL efficiently load, process, analyze large-scale spatial data across machines. apache.sedona R package exposes interface Apache Sedona sparklyr enabling higher-level access dplyr backend familiar R functions.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"R Interface for Apache Sedona","text":"use Apache Sedona R, just need install apache.sedona package; Spark dependencies managed directly package.","code":"# Install released version from CRAN install.packages(\"apache.sedona\")"},{"path":"/index.html","id":"development-version","dir":"","previous_headings":"Installation","what":"Development version","title":"R Interface for Apache Sedona","text":"use development version, need latest version package Apache Sedona jars. get latest R package GitHub: get latest Sedona jars can: Compile Sedona code , see Compile code Get latest generated jars GitHub ‘Java build’ action; click latest run, generated jars bottom page path sedona-spark-shaded jars needs put SEDONA_JAR_FILES environment variables (see ).","code":"# Install development version from GitHub devtools::install_github(\"apache/sedona/R\")"},{"path":"/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"R Interface for Apache Sedona","text":"spark_read_* functions read geospatial data Spark Dataframes. resulting Spark dataframe object can modified using dplyr verbs familiar many R users. addition, spatial UDFs supported Sedona can inter-operate seamlessly functions supported sparklyr’s dbplyr SQL translation env. example, code finds average area polygons polygon_sdf: first time load Sedona, Spark download dependent jars, can take minutes cause connection timeout. can either retry (jars already downloaded cached) increase \"sparklyr.connect.timeout\" parameter sparklyr config. Notice can open many interesting possibilities. example, one can extract ML features geospatial data Spark dataframes, build ML pipeline using ml_* family functions sparklyr work features, output ML model happens geospatial object well, one can even apply visualization routines apache.sedona visualize difference predicted geometry corresponding ground truth.","code":"library(sparklyr) library(apache.sedona)  ## Only if using development version: Sys.setenv(\"SEDONA_JAR_FILES\" = \"<path to sedona-spark-shaded jar>\")  sc <- spark_connect(master = \"local\") polygon_sdf <- spark_read_geojson(sc, location = \"/tmp/polygon.json\") mean_area_sdf <- polygon_sdf %>%   dplyr::summarize(mean_area = mean(ST_Area(geometry))) print(mean_area_sdf)"},{"path":"/reference/apache.sedona-package.html","id":null,"dir":"Reference","previous_headings":"","what":"apache.sedona: R Interface for Apache Sedona — apache.sedona-package","title":"apache.sedona: R Interface for Apache Sedona — apache.sedona-package","text":"R interface 'Apache Sedona' based 'sparklyr' (https://sedona.apache.org).","code":""},{"path":[]},{"path":"/reference/apache.sedona-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"apache.sedona: R Interface for Apache Sedona — apache.sedona-package","text":"Maintainer:  Apache Sedona private@sedona.apache.org Authors: Yitao Li yitao@rstudio.com (ORCID) [copyright holder] contributors: Jia Yu jiayu@apache.org [contributor, copyright holder] Apache Software Foundation [copyright holder] RStudio [copyright holder]","code":""},{"path":"/reference/approx_count.html","id":null,"dir":"Reference","previous_headings":"","what":"Find the approximate total number of records within a Spatial RDD. — approx_count","title":"Find the approximate total number of records within a Spatial RDD. — approx_count","text":"Given Sedona spatial RDD, find (possibly approximated) number total records within .","code":""},{"path":"/reference/approx_count.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find the approximate total number of records within a Spatial RDD. — approx_count","text":"","code":"approx_count(x)"},{"path":"/reference/approx_count.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find the approximate total number of records within a Spatial RDD. — approx_count","text":"x Sedona spatial RDD.","code":""},{"path":"/reference/approx_count.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find the approximate total number of records within a Spatial RDD. — approx_count","text":"Approximate number records within SpatialRDD.","code":""},{"path":[]},{"path":"/reference/approx_count.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find the approximate total number of records within a Spatial RDD. — approx_count","text":"","code":"library(sparklyr) #>  #> Attaching package: ‘sparklyr’ #> The following object is masked from ‘package:stats’: #>  #>     filter library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   input_location <- \"/dev/null\" # replace it with the path to your input file   rdd <- sedona_read_shapefile_to_typed_rdd(     sc,     location = input_location, type = \"polygon\"   )   approx_cnt <- approx_count(rdd) }"},{"path":"/reference/crs_transform.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform a CRS transformation. — crs_transform","title":"Perform a CRS transformation. — crs_transform","text":"Transform data within spatial RDD one coordinate reference system another. uses lon/lat order since v1.5.0. , used lat/lon","code":""},{"path":"/reference/crs_transform.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform a CRS transformation. — crs_transform","text":"","code":"crs_transform(x, src_epsg_crs_code, dst_epsg_crs_code, strict = FALSE)"},{"path":"/reference/crs_transform.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform a CRS transformation. — crs_transform","text":"x spatial RDD processed. src_epsg_crs_code Coordinate reference system transform (e.g., \"epsg:4326\", \"epsg:3857\", etc). dst_epsg_crs_code Coordinate reference system transform . (e.g., \"epsg:4326\", \"epsg:3857\", etc). strict FALSE (default), ignore \"Bursa-Wolf Parameters Required\" error.","code":""},{"path":"/reference/crs_transform.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform a CRS transformation. — crs_transform","text":"transformed SpatialRDD.","code":""},{"path":"/reference/crs_transform.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Perform a CRS transformation. — crs_transform","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   input_location <- \"/dev/null\" # replace it with the path to your input file   rdd <- sedona_read_geojson_to_typed_rdd(     sc,     location = input_location, type = \"polygon\"   )   crs_transform(     rdd,     src_epsg_crs_code = \"epsg:4326\", dst_epsg_crs_code = \"epsg:3857\"   ) }"},{"path":"/reference/minimum_bounding_box.html","id":null,"dir":"Reference","previous_headings":"","what":"Find the minimal bounding box of a geometry. — minimum_bounding_box","title":"Find the minimal bounding box of a geometry. — minimum_bounding_box","text":"Given Sedona spatial RDD, find axis-aligned minimal bounding box geometry represented RDD.","code":""},{"path":"/reference/minimum_bounding_box.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find the minimal bounding box of a geometry. — minimum_bounding_box","text":"","code":"minimum_bounding_box(x)"},{"path":"/reference/minimum_bounding_box.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find the minimal bounding box of a geometry. — minimum_bounding_box","text":"x Sedona spatial RDD.","code":""},{"path":"/reference/minimum_bounding_box.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find the minimal bounding box of a geometry. — minimum_bounding_box","text":"minimum bounding box object.","code":""},{"path":[]},{"path":"/reference/minimum_bounding_box.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find the minimal bounding box of a geometry. — minimum_bounding_box","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   input_location <- \"/dev/null\" # replace it with the path to your input file   rdd <- sedona_read_shapefile_to_typed_rdd(     sc,     location = input_location, type = \"polygon\"   )   boundary <- minimum_bounding_box(rdd) }"},{"path":"/reference/new_bounding_box.html","id":null,"dir":"Reference","previous_headings":"","what":"Construct a bounding box object. — new_bounding_box","title":"Construct a bounding box object. — new_bounding_box","text":"Construct axis-aligned rectangular bounding box object.","code":""},{"path":"/reference/new_bounding_box.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Construct a bounding box object. — new_bounding_box","text":"","code":"new_bounding_box(sc, min_x = -Inf, max_x = Inf, min_y = -Inf, max_y = Inf)"},{"path":"/reference/new_bounding_box.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Construct a bounding box object. — new_bounding_box","text":"sc Spark connection. min_x Minimum x-value bounding box, can +/- Inf. max_x Maximum x-value bounding box, can +/- Inf. min_y Minimum y-value bounding box, can +/- Inf. max_y Maximum y-value bounding box, can +/- Inf.","code":""},{"path":"/reference/new_bounding_box.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Construct a bounding box object. — new_bounding_box","text":"bounding box object.","code":""},{"path":"/reference/new_bounding_box.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Construct a bounding box object. — new_bounding_box","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\") bb <- new_bounding_box(sc, -1, 1, -1, 1)"},{"path":"/reference/sdf_register.spatial_rdd.html","id":null,"dir":"Reference","previous_headings":"","what":"Import data from a spatial RDD into a Spark Dataframe. — sdf_register.spatial_rdd","title":"Import data from a spatial RDD into a Spark Dataframe. — sdf_register.spatial_rdd","text":"Import data spatial RDD (possibly non-spatial attributes) Spark Dataframe. sdf_register: method sparklyr's sdf_register handle Spatial RDD .spark.dataframe: lower level function fine-grained control non-spatial columns","code":""},{"path":"/reference/sdf_register.spatial_rdd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Import data from a spatial RDD into a Spark Dataframe. — sdf_register.spatial_rdd","text":"","code":"# S3 method for class 'spatial_rdd' sdf_register(x, name = NULL)  as.spark.dataframe(x, non_spatial_cols = NULL, name = NULL)"},{"path":"/reference/sdf_register.spatial_rdd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Import data from a spatial RDD into a Spark Dataframe. — sdf_register.spatial_rdd","text":"x spatial RDD. name Name assign resulting Spark temporary view. unspecified, random name assigned. non_spatial_cols Column names non-spatial attributes resulting Spark Dataframe. default (NULL) import field names property exists, particular shapefiles.","code":""},{"path":"/reference/sdf_register.spatial_rdd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Import data from a spatial RDD into a Spark Dataframe. — sdf_register.spatial_rdd","text":"Spark Dataframe containing imported spatial data.","code":""},{"path":"/reference/sdf_register.spatial_rdd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Import data from a spatial RDD into a Spark Dataframe. — sdf_register.spatial_rdd","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   input_location <- \"/dev/null\" # replace it with the path to your input file   rdd <- sedona_read_geojson_to_typed_rdd(     sc,     location = input_location,     type = \"polygon\"   )   sdf <- sdf_register(rdd)    input_location <- \"/dev/null\" # replace it with the path to your input file   rdd <- sedona_read_dsv_to_typed_rdd(     sc,     location = input_location,     delimiter = \",\",     type = \"point\",     first_spatial_col_index = 1L,     repartition = 5   )   sdf <- as.spark.dataframe(rdd, non_spatial_cols = c(\"attr1\", \"attr2\")) }"},{"path":"/reference/sedona_apply_spatial_partitioner.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply a spatial partitioner to a Sedona spatial RDD. — sedona_apply_spatial_partitioner","title":"Apply a spatial partitioner to a Sedona spatial RDD. — sedona_apply_spatial_partitioner","text":"Given Sedona spatial RDD, partition content using spatial partitioner.","code":""},{"path":"/reference/sedona_apply_spatial_partitioner.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply a spatial partitioner to a Sedona spatial RDD. — sedona_apply_spatial_partitioner","text":"","code":"sedona_apply_spatial_partitioner(   rdd,   partitioner = c(\"quadtree\", \"kdbtree\"),   max_levels = NULL )"},{"path":"/reference/sedona_apply_spatial_partitioner.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply a spatial partitioner to a Sedona spatial RDD. — sedona_apply_spatial_partitioner","text":"rdd spatial RDD partitioned. partitioner name grid type use (currently \"quadtree\" \"kdbtree\" supported) org.apache.sedona.core.spatialPartitioning.SpatialPartitioner JVM object. latter option relevant advanced use cases involving custom spatial partitioner. max_levels Maximum number levels partitioning tree data structure. NULL (default), use current number partitions within rdd maximum number levels. Specifying max_levels unsupported use cases involving custom spatial partitioner scenarios partitioner object already maximum number levels set well-defined way override existing setting partitioning data structure.","code":""},{"path":"/reference/sedona_apply_spatial_partitioner.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply a spatial partitioner to a Sedona spatial RDD. — sedona_apply_spatial_partitioner","text":"spatially partitioned SpatialRDD.","code":""},{"path":"/reference/sedona_apply_spatial_partitioner.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply a spatial partitioner to a Sedona spatial RDD. — sedona_apply_spatial_partitioner","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   input_location <- \"/dev/null\" # replace it with the path to your input file   rdd <- sedona_read_dsv_to_typed_rdd(     sc,     location = input_location,     delimiter = \",\",     type = \"point\",     first_spatial_col_index = 1L   )   sedona_apply_spatial_partitioner(rdd, partitioner = \"kdbtree\") }"},{"path":"/reference/sedona_build_index.html","id":null,"dir":"Reference","previous_headings":"","what":"Build an index on a Sedona spatial RDD. — sedona_build_index","title":"Build an index on a Sedona spatial RDD. — sedona_build_index","text":"Given Sedona spatial RDD, build type index specified partition(s).","code":""},{"path":"/reference/sedona_build_index.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build an index on a Sedona spatial RDD. — sedona_build_index","text":"","code":"sedona_build_index(   rdd,   type = c(\"quadtree\", \"rtree\"),   index_spatial_partitions = TRUE )"},{"path":"/reference/sedona_build_index.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build an index on a Sedona spatial RDD. — sedona_build_index","text":"rdd spatial RDD indexed. type type index build. Currently \"quadtree\" \"rtree\" supported. index_spatial_partitions RDD already partitioned using spatial partitioner, index spatial partition within RDD instead partitions within raw RDD associated underlying spatial data source. Default: TRUE. Notice option irrelevant input RDD partitioned using spatial partitioner yet.","code":""},{"path":"/reference/sedona_build_index.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build an index on a Sedona spatial RDD. — sedona_build_index","text":"spatial index object.","code":""},{"path":"/reference/sedona_build_index.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build an index on a Sedona spatial RDD. — sedona_build_index","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   input_location <- \"/dev/null\" # replace it with the path to your input file   rdd <- sedona_read_shapefile_to_typed_rdd(     sc,     location = input_location,     type = \"polygon\"   )   sedona_build_index(rdd, type = \"rtree\") }"},{"path":"/reference/sedona_knn_query.html","id":null,"dir":"Reference","previous_headings":"","what":"Query the k nearest spatial objects. — sedona_knn_query","title":"Query the k nearest spatial objects. — sedona_knn_query","text":"Given spatial RDD, query object x, integer k, find k nearest spatial objects within RDD x (distance x another geometrical object measured minimum possible length line segment connecting 2 objects).","code":""},{"path":"/reference/sedona_knn_query.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Query the k nearest spatial objects. — sedona_knn_query","text":"","code":"sedona_knn_query(   rdd,   x,   k,   index_type = c(\"quadtree\", \"rtree\"),   result_type = c(\"rdd\", \"sdf\", \"raw\") )"},{"path":"/reference/sedona_knn_query.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Query the k nearest spatial objects. — sedona_knn_query","text":"rdd Sedona spatial RDD. x query object. k Number nearest spatail objects return. index_type Index use facilitate KNN query. NULL, build additional spatial index top x. Supported index types \"quadtree\" \"rtree\". result_type Type result return. \"rdd\" (default), k nearest objects returned Sedona spatial RDD. \"sdf\", Spark dataframe containing k nearest objects returned. \"raw\", list k nearest objects returned. element within list JVM object type org.locationtech.jts.geom.Geometry.","code":""},{"path":"/reference/sedona_knn_query.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Query the k nearest spatial objects. — sedona_knn_query","text":"KNN query result.","code":""},{"path":[]},{"path":"/reference/sedona_knn_query.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Query the k nearest spatial objects. — sedona_knn_query","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   knn_query_pt_x <- -84.01   knn_query_pt_y <- 34.01   knn_query_pt_tbl <- sdf_sql(     sc,     sprintf(       \"SELECT ST_GeomFromText(\\\"POINT(%f %f)\\\") AS `pt`\",       knn_query_pt_x,       knn_query_pt_y     )   ) %>%       collect()   knn_query_pt <- knn_query_pt_tbl$pt[[1]]   input_location <- \"/dev/null\" # replace it with the path to your input file   rdd <- sedona_read_geojson_to_typed_rdd(     sc,     location = input_location,     type = \"polygon\"   )   knn_result_sdf <- sedona_knn_query(     rdd,     x = knn_query_pt, k = 3, index_type = \"rtree\", result_type = \"sdf\"   ) }"},{"path":"/reference/sedona_range_query.html","id":null,"dir":"Reference","previous_headings":"","what":"Execute a range query. — sedona_range_query","title":"Execute a range query. — sedona_range_query","text":"Given spatial RDD query object x, find spatial objects within RDD covered x intersect x.","code":""},{"path":"/reference/sedona_range_query.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Execute a range query. — sedona_range_query","text":"","code":"sedona_range_query(   rdd,   x,   query_type = c(\"cover\", \"intersect\"),   index_type = c(\"quadtree\", \"rtree\"),   result_type = c(\"rdd\", \"sdf\", \"raw\") )"},{"path":"/reference/sedona_range_query.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Execute a range query. — sedona_range_query","text":"rdd Sedona spatial RDD. x query object. query_type Type spatial relationship involved query. Currently \"cover\" \"intersect\" supported. index_type Index use facilitate KNN query. NULL, build additional spatial index top x. Supported index types \"quadtree\" \"rtree\". result_type Type result return. \"rdd\" (default), k nearest objects returned Sedona spatial RDD. \"sdf\", Spark dataframe containing k nearest objects returned. \"raw\", list k nearest objects returned. element within list JVM object type org.locationtech.jts.geom.Geometry.","code":""},{"path":"/reference/sedona_range_query.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Execute a range query. — sedona_range_query","text":"range query result.","code":""},{"path":[]},{"path":"/reference/sedona_range_query.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Execute a range query. — sedona_range_query","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   range_query_min_x <- -87   range_query_max_x <- -50   range_query_min_y <- 34   range_query_max_y <- 54   geom_factory <- invoke_new(     sc,     \"org.locationtech.jts.geom.GeometryFactory\"   )   range_query_polygon <- invoke_new(     sc,     \"org.locationtech.jts.geom.Envelope\",     range_query_min_x,     range_query_max_x,     range_query_min_y,     range_query_max_y   ) %>%     invoke(geom_factory, \"toGeometry\", .)   input_location <- \"/dev/null\" # replace it with the path to your input file   rdd <- sedona_read_geojson_to_typed_rdd(     sc,     location = input_location,     type = \"polygon\"   )   range_query_result_sdf <- sedona_range_query(     rdd,     x = range_query_polygon,     query_type = \"intersect\",     index_type = \"rtree\",     result_type = \"sdf\"   ) }"},{"path":"/reference/sedona_read_dsv_to_typed_rdd.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a typed SpatialRDD from a delimiter-separated values data source. — sedona_read_dsv_to_typed_rdd","title":"Create a typed SpatialRDD from a delimiter-separated values data source. — sedona_read_dsv_to_typed_rdd","text":"Create typed SpatialRDD (namely, PointRDD, PolygonRDD, LineStringRDD) data source containing delimiter-separated values. data source can contain spatial attributes (e.g., longitude latidude) attributes. Currently inputs spatial attributes occupying contiguous range columns (.e., [first_spatial_col_index, last_spatial_col_index]) supported.","code":""},{"path":"/reference/sedona_read_dsv_to_typed_rdd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a typed SpatialRDD from a delimiter-separated values data source. — sedona_read_dsv_to_typed_rdd","text":"","code":"sedona_read_dsv_to_typed_rdd(   sc,   location,   delimiter = c(\",\", \"\\t\", \"?\", \"'\", \"\\\"\", \"_\", \"-\", \"%\", \"~\", \"|\", \";\"),   type = c(\"point\", \"polygon\", \"linestring\"),   first_spatial_col_index = 0L,   last_spatial_col_index = NULL,   has_non_spatial_attrs = TRUE,   storage_level = \"MEMORY_ONLY\",   repartition = 1L )"},{"path":"/reference/sedona_read_dsv_to_typed_rdd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a typed SpatialRDD from a delimiter-separated values data source. — sedona_read_dsv_to_typed_rdd","text":"sc spark_connection. location Location data source. delimiter Delimiter within record. Must one ',', '\\t', '?', '\\”, '\"', '_', '-', '%', '~', '|', ';' type Type SpatialRDD (must one \"point\", \"polygon\", \"linestring\". first_spatial_col_index Zero-based index left-column containing spatial attributes (default: 0). last_spatial_col_index Zero-based index right-column containing spatial attributes (default: NULL). Note last_spatial_col_index need specified creating PointRDD automatically implied value (first_spatial_col_index + 1). types RDDs, last_spatial_col_index unspecified, assume value -1 (.e., last input columns). has_non_spatial_attrs Whether input contains non-spatial attributes. storage_level Storage level RDD (default: MEMORY_ONLY). repartition minimum number partitions resulting RDD (default: 1).","code":""},{"path":"/reference/sedona_read_dsv_to_typed_rdd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a typed SpatialRDD from a delimiter-separated values data source. — sedona_read_dsv_to_typed_rdd","text":"typed SpatialRDD.","code":""},{"path":[]},{"path":"/reference/sedona_read_dsv_to_typed_rdd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a typed SpatialRDD from a delimiter-separated values data source. — sedona_read_dsv_to_typed_rdd","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   input_location <- \"/dev/null\" # replace it with the path to your csv file   rdd <- sedona_read_dsv_to_typed_rdd(     sc,     location = input_location,     delimiter = \",\",     type = \"point\",     first_spatial_col_index = 1L   ) }"},{"path":"/reference/sedona_read_geojson.html","id":null,"dir":"Reference","previous_headings":"","what":"Read geospatial data into a Spatial RDD — sedona_read_geojson","title":"Read geospatial data into a Spatial RDD — sedona_read_geojson","text":"Import spatial object external data source Sedona SpatialRDD. sedona_read_shapefile: shapefile sedona_read_geojson: geojson file sedona_read_wkt: geojson file sedona_read_wkb: geojson file","code":""},{"path":"/reference/sedona_read_geojson.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read geospatial data into a Spatial RDD — sedona_read_geojson","text":"","code":"sedona_read_geojson(   sc,   location,   allow_invalid_geometries = TRUE,   skip_syntactically_invalid_geometries = TRUE,   storage_level = \"MEMORY_ONLY\",   repartition = 1L )  sedona_read_wkb(   sc,   location,   wkb_col_idx = 0L,   allow_invalid_geometries = TRUE,   skip_syntactically_invalid_geometries = TRUE,   storage_level = \"MEMORY_ONLY\",   repartition = 1L )  sedona_read_wkt(   sc,   location,   wkt_col_idx = 0L,   allow_invalid_geometries = TRUE,   skip_syntactically_invalid_geometries = TRUE,   storage_level = \"MEMORY_ONLY\",   repartition = 1L )  sedona_read_shapefile(sc, location, storage_level = \"MEMORY_ONLY\")"},{"path":"/reference/sedona_read_geojson.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read geospatial data into a Spatial RDD — sedona_read_geojson","text":"sc spark_connection. location Location data source. allow_invalid_geometries Whether allow topology-invalid geometries exist resulting RDD. skip_syntactically_invalid_geometries Whether allows Sedona automatically skip syntax-invalid geometries, rather throwing errorings. storage_level Storage level RDD (default: MEMORY_ONLY). repartition minimum number partitions resulting RDD (default: 1). wkb_col_idx Zero-based index column containing hex-encoded WKB data (default: 0). wkt_col_idx Zero-based index column containing hex-encoded WKB data (default: 0).","code":""},{"path":"/reference/sedona_read_geojson.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read geospatial data into a Spatial RDD — sedona_read_geojson","text":"SpatialRDD.","code":""},{"path":[]},{"path":"/reference/sedona_read_geojson.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read geospatial data into a Spatial RDD — sedona_read_geojson","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   input_location <- \"/dev/null\" # replace it with the path to your input file   rdd <- sedona_read_geojson(sc, location = input_location) }"},{"path":"/reference/sedona_read_shapefile_to_typed_rdd.html","id":null,"dir":"Reference","previous_headings":"","what":"(Deprecated) Create a typed SpatialRDD from a shapefile or geojson data source. — sedona_read_shapefile_to_typed_rdd","title":"(Deprecated) Create a typed SpatialRDD from a shapefile or geojson data source. — sedona_read_shapefile_to_typed_rdd","text":"Constructors typed RDD (PointRDD, PolygonRDD, LineStringRDD) soft deprecated, use non-types versions Create typed SpatialRDD (namely, PointRDD, PolygonRDD, LineStringRDD) sedona_read_shapefile_to_typed_rdd: shapefile data source sedona_read_geojson_to_typed_rdd: GeoJSON data source","code":""},{"path":"/reference/sedona_read_shapefile_to_typed_rdd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"(Deprecated) Create a typed SpatialRDD from a shapefile or geojson data source. — sedona_read_shapefile_to_typed_rdd","text":"","code":"sedona_read_shapefile_to_typed_rdd(   sc,   location,   type = c(\"point\", \"polygon\", \"linestring\"),   storage_level = \"MEMORY_ONLY\" )  sedona_read_geojson_to_typed_rdd(   sc,   location,   type = c(\"point\", \"polygon\", \"linestring\"),   has_non_spatial_attrs = TRUE,   storage_level = \"MEMORY_ONLY\",   repartition = 1L )"},{"path":"/reference/sedona_read_shapefile_to_typed_rdd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"(Deprecated) Create a typed SpatialRDD from a shapefile or geojson data source. — sedona_read_shapefile_to_typed_rdd","text":"sc spark_connection. location Location data source. type Type SpatialRDD (must one \"point\", \"polygon\", \"linestring\". storage_level Storage level RDD (default: MEMORY_ONLY). has_non_spatial_attrs Whether input contains non-spatial attributes. repartition minimum number partitions resulting RDD (default: 1).","code":""},{"path":"/reference/sedona_read_shapefile_to_typed_rdd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"(Deprecated) Create a typed SpatialRDD from a shapefile or geojson data source. — sedona_read_shapefile_to_typed_rdd","text":"typed SpatialRDD.","code":""},{"path":[]},{"path":"/reference/sedona_read_shapefile_to_typed_rdd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"(Deprecated) Create a typed SpatialRDD from a shapefile or geojson data source. — sedona_read_shapefile_to_typed_rdd","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   input_location <- \"/dev/null\" # replace it with the path to your shapefile   rdd <- sedona_read_shapefile_to_typed_rdd(     sc,     location = input_location, type = \"polygon\"   ) }"},{"path":"/reference/sedona_render_choropleth_map.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize a Sedona spatial RDD using a choropleth map. — sedona_render_choropleth_map","title":"Visualize a Sedona spatial RDD using a choropleth map. — sedona_render_choropleth_map","text":"Generate choropleth map pair RDD assigning integral values polygons.","code":""},{"path":"/reference/sedona_render_choropleth_map.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize a Sedona spatial RDD using a choropleth map. — sedona_render_choropleth_map","text":"","code":"sedona_render_choropleth_map(   pair_rdd,   resolution_x,   resolution_y,   output_location,   output_format = c(\"png\", \"gif\", \"svg\"),   boundary = NULL,   color_of_variation = c(\"red\", \"green\", \"blue\"),   base_color = c(0, 0, 0),   shade = TRUE,   reverse_coords = FALSE,   overlay = NULL,   browse = interactive() )"},{"path":"/reference/sedona_render_choropleth_map.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize a Sedona spatial RDD using a choropleth map. — sedona_render_choropleth_map","text":"pair_rdd pair RDD Sedona Polygon objects keys java.lang.Long values. resolution_x Resolution x-axis. resolution_y Resolution y-axis. output_location Location output image. desired path image file excluding extension file name. output_format File format output image. Currently \"png\", \"gif\", \"svg\" formats supported (default: \"png\"). boundary render data within given rectangular boundary. boundary parameter can set either numeric vector c(min_x, max_y, min_y, max_y) values, bounding box object e.g., new_bounding_box(sc, min_x, max_y, min_y, max_y), NULL (default). boundary NULL, minimum bounding box input spatial RDD computed used boundary rendering. color_of_variation color channel vary depending values data points. Must one \"red\", \"green\", \"blue\". Default: red. base_color Color data point value 0. Must numeric vector length 3 specifying values red, green, blue channels. Default: c(0, 0, 0). shade Whether data point larger magnitude displayed darker color. Default: TRUE. reverse_coords Whether reverse spatial coordinates plot (default: FALSE). overlay viz_op object containing raster image displayed top resulting image. browse Whether open rendered image browser (default: interactive()).","code":""},{"path":"/reference/sedona_render_choropleth_map.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Visualize a Sedona spatial RDD using a choropleth map. — sedona_render_choropleth_map","text":"return value.","code":""},{"path":[]},{"path":"/reference/sedona_render_choropleth_map.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualize a Sedona spatial RDD using a choropleth map. — sedona_render_choropleth_map","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   pt_input_location <- \"/dev/null\" # replace it with the path to your input file   pt_rdd <- sedona_read_dsv_to_typed_rdd(     sc,     location = pt_input_location,     type = \"point\",     first_spatial_col_index = 1   )   polygon_input_location <- \"/dev/null\" # replace it with the path to your input file   polygon_rdd <- sedona_read_geojson_to_typed_rdd(     sc,     location = polygon_input_location,     type = \"polygon\"   )   join_result_rdd <- sedona_spatial_join_count_by_key(     pt_rdd,     polygon_rdd,     join_type = \"intersect\",     partitioner = \"quadtree\"   )   sedona_render_choropleth_map(     join_result_rdd,     400,     200,     output_location = tempfile(\"choropleth-map-\"),     boundary = c(-86.8, -86.6, 33.4, 33.6),     base_color = c(255, 255, 255)   ) }"},{"path":"/reference/sedona_render_heatmap.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize a Sedona spatial RDD using a heatmap. — sedona_render_heatmap","title":"Visualize a Sedona spatial RDD using a heatmap. — sedona_render_heatmap","text":"Generate heatmap geometrical object(s) within Sedona spatial RDD.","code":""},{"path":"/reference/sedona_render_heatmap.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize a Sedona spatial RDD using a heatmap. — sedona_render_heatmap","text":"","code":"sedona_render_heatmap(   rdd,   resolution_x,   resolution_y,   output_location,   output_format = c(\"png\", \"gif\", \"svg\"),   boundary = NULL,   blur_radius = 10L,   overlay = NULL,   browse = interactive() )"},{"path":"/reference/sedona_render_heatmap.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize a Sedona spatial RDD using a heatmap. — sedona_render_heatmap","text":"rdd Sedona spatial RDD. resolution_x Resolution x-axis. resolution_y Resolution y-axis. output_location Location output image. desired path image file excluding extension file name. output_format File format output image. Currently \"png\", \"gif\", \"svg\" formats supported (default: \"png\"). boundary render data within given rectangular boundary. boundary parameter can set either numeric vector c(min_x, max_y, min_y, max_y) values, bounding box object e.g., new_bounding_box(sc, min_x, max_y, min_y, max_y), NULL (default). boundary NULL, minimum bounding box input spatial RDD computed used boundary rendering. blur_radius Controls radius Gaussian blur resulting heatmap. overlay viz_op object containing raster image displayed top resulting image. browse Whether open rendered image browser (default: interactive()).","code":""},{"path":"/reference/sedona_render_heatmap.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Visualize a Sedona spatial RDD using a heatmap. — sedona_render_heatmap","text":"return value.","code":""},{"path":[]},{"path":"/reference/sedona_render_heatmap.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualize a Sedona spatial RDD using a heatmap. — sedona_render_heatmap","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   input_location <- \"/dev/null\" # replace it with the path to your input file   rdd <- sedona_read_dsv_to_typed_rdd(     sc,     location = input_location,     type = \"point\"   )    sedona_render_heatmap(     rdd,     resolution_x = 800,     resolution_y = 600,     output_location = tempfile(\"points-\"),     output_format = \"png\",     boundary = c(-91, -84, 30, 35),     blur_radius = 10   ) }"},{"path":"/reference/sedona_render_scatter_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize a Sedona spatial RDD using a scatter plot. — sedona_render_scatter_plot","title":"Visualize a Sedona spatial RDD using a scatter plot. — sedona_render_scatter_plot","text":"Generate scatter plot geometrical object(s) within Sedona spatial RDD.","code":""},{"path":"/reference/sedona_render_scatter_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize a Sedona spatial RDD using a scatter plot. — sedona_render_scatter_plot","text":"","code":"sedona_render_scatter_plot(   rdd,   resolution_x,   resolution_y,   output_location,   output_format = c(\"png\", \"gif\", \"svg\"),   boundary = NULL,   color_of_variation = c(\"red\", \"green\", \"blue\"),   base_color = c(0, 0, 0),   shade = TRUE,   reverse_coords = FALSE,   overlay = NULL,   browse = interactive() )"},{"path":"/reference/sedona_render_scatter_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize a Sedona spatial RDD using a scatter plot. — sedona_render_scatter_plot","text":"rdd Sedona spatial RDD. resolution_x Resolution x-axis. resolution_y Resolution y-axis. output_location Location output image. desired path image file excluding extension file name. output_format File format output image. Currently \"png\", \"gif\", \"svg\" formats supported (default: \"png\"). boundary render data within given rectangular boundary. boundary parameter can set either numeric vector c(min_x, max_y, min_y, max_y) values, bounding box object e.g., new_bounding_box(sc, min_x, max_y, min_y, max_y), NULL (default). boundary NULL, minimum bounding box input spatial RDD computed used boundary rendering. color_of_variation color channel vary depending values data points. Must one \"red\", \"green\", \"blue\". Default: red. base_color Color data point value 0. Must numeric vector length 3 specifying values red, green, blue channels. Default: c(0, 0, 0). shade Whether data point larger magnitude displayed darker color. Default: TRUE. reverse_coords Whether reverse spatial coordinates plot (default: FALSE). overlay viz_op object containing raster image displayed top resulting image. browse Whether open rendered image browser (default: interactive()).","code":""},{"path":"/reference/sedona_render_scatter_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Visualize a Sedona spatial RDD using a scatter plot. — sedona_render_scatter_plot","text":"return value.","code":""},{"path":[]},{"path":"/reference/sedona_render_scatter_plot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Visualize a Sedona spatial RDD using a scatter plot. — sedona_render_scatter_plot","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   input_location <- \"/dev/null\" # replace it with the path to your input file   rdd <- sedona_read_dsv_to_typed_rdd(     sc,     location = input_location,     type = \"point\"   )    sedona_render_scatter_plot(     rdd,     resolution_x = 800,     resolution_y = 600,     output_location = tempfile(\"points-\"),     output_format = \"png\",     boundary = c(-91, -84, 30, 35)   ) }"},{"path":"/reference/sedona_save_spatial_rdd.html","id":null,"dir":"Reference","previous_headings":"","what":"Save a Spark dataframe containing exactly 1 spatial column into a file. — sedona_save_spatial_rdd","title":"Save a Spark dataframe containing exactly 1 spatial column into a file. — sedona_save_spatial_rdd","text":"Export serialized data Spark dataframe containing exactly 1 spatial column file.","code":""},{"path":"/reference/sedona_save_spatial_rdd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save a Spark dataframe containing exactly 1 spatial column into a file. — sedona_save_spatial_rdd","text":"","code":"sedona_save_spatial_rdd(   x,   spatial_col,   output_location,   output_format = c(\"wkb\", \"wkt\", \"geojson\") )"},{"path":"/reference/sedona_save_spatial_rdd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save a Spark dataframe containing exactly 1 spatial column into a file. — sedona_save_spatial_rdd","text":"x Spark dataframe object sparklyr dplyr expression representing Spark SQL query. spatial_col name spatial column. output_location Location output file. output_format Format output.","code":""},{"path":"/reference/sedona_save_spatial_rdd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Save a Spark dataframe containing exactly 1 spatial column into a file. — sedona_save_spatial_rdd","text":"return value.","code":""},{"path":[]},{"path":"/reference/sedona_save_spatial_rdd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Save a Spark dataframe containing exactly 1 spatial column into a file. — sedona_save_spatial_rdd","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   tbl <- dplyr::tbl(     sc,     dplyr::sql(\"SELECT ST_GeomFromText('POINT(-71.064544 42.28787)') AS `pt`\")   )   sedona_save_spatial_rdd(     tbl %>% dplyr::mutate(id = 1),     spatial_col = \"pt\",     output_location = \"/tmp/pts.wkb\",     output_format = \"wkb\"   ) }"},{"path":"/reference/sedona_spatial_join.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform a spatial join operation on two Sedona spatial RDDs. — sedona_spatial_join","title":"Perform a spatial join operation on two Sedona spatial RDDs. — sedona_spatial_join","text":"Given spatial_rdd query_window_rdd, return pair RDD containing pairs geometrical elements (p, q) p element spatial_rdd, q element query_window_rdd, (p, q) satisfies spatial relation specified join_type.","code":""},{"path":"/reference/sedona_spatial_join.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform a spatial join operation on two Sedona spatial RDDs. — sedona_spatial_join","text":"","code":"sedona_spatial_join(   spatial_rdd,   query_window_rdd,   join_type = c(\"contain\", \"intersect\"),   partitioner = c(\"quadtree\", \"kdbtree\"),   index_type = c(\"quadtree\", \"rtree\") )"},{"path":"/reference/sedona_spatial_join.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform a spatial join operation on two Sedona spatial RDDs. — sedona_spatial_join","text":"spatial_rdd Spatial RDD containing geometries queried. query_window_rdd Spatial RDD containing query window(s). join_type Type join query (must either \"contain\" \"intersect\"). join_type \"contain\", geometry spatial_rdd match geometry query_window_rdd former fully contained latter. join_type \"intersect\", geometry spatial_rdd match geometry query_window_rdd former intersects latter. partitioner Spatial partitioning apply spatial_rdd query_window_rdd facilitate join query. Can either grid type (currently \"quadtree\" \"kdbtree\" supported) custom spatial partitioner object. partitioner NULL, assume spatial partitioner applied spatial_rdd query_window_rdd already skip partitioning step. index_type Controls spatial_rdd query_window_rdd indexed (unless indexed already). \"NONE\", index constructed matching geometries identified doubly nested- loop iterating possible pairs elements spatial_rdd query_window_rdd, inefficient large data sets.","code":""},{"path":"/reference/sedona_spatial_join.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform a spatial join operation on two Sedona spatial RDDs. — sedona_spatial_join","text":"spatial RDD containing join result.","code":""},{"path":[]},{"path":"/reference/sedona_spatial_join.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Perform a spatial join operation on two Sedona spatial RDDs. — sedona_spatial_join","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   input_location <- \"/dev/null\" # replace it with the path to your input file   rdd <- sedona_read_dsv_to_typed_rdd(     sc,     location = input_location,     delimiter = \",\",     type = \"point\",     first_spatial_col_index = 1L   )   query_rdd_input_location <- \"/dev/null\" # replace it with the path to your input file   query_rdd <- sedona_read_shapefile_to_typed_rdd(     sc,     location = query_rdd_input_location,     type = \"polygon\"   )   join_result_rdd <- sedona_spatial_join(     rdd,     query_rdd,     join_type = \"intersect\",     partitioner = \"quadtree\"   ) }"},{"path":"/reference/sedona_spatial_join_count_by_key.html","id":null,"dir":"Reference","previous_headings":"","what":"Perform a spatial count-by-key operation based on two Sedona spatial RDDs. — sedona_spatial_join_count_by_key","title":"Perform a spatial count-by-key operation based on two Sedona spatial RDDs. — sedona_spatial_join_count_by_key","text":"element p spatial_rdd, count number unique elements q query_window_rdd (p, q) satisfies spatial relation specified join_type.","code":""},{"path":"/reference/sedona_spatial_join_count_by_key.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Perform a spatial count-by-key operation based on two Sedona spatial RDDs. — sedona_spatial_join_count_by_key","text":"","code":"sedona_spatial_join_count_by_key(   spatial_rdd,   query_window_rdd,   join_type = c(\"contain\", \"intersect\"),   partitioner = c(\"quadtree\", \"kdbtree\"),   index_type = c(\"quadtree\", \"rtree\") )"},{"path":"/reference/sedona_spatial_join_count_by_key.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Perform a spatial count-by-key operation based on two Sedona spatial RDDs. — sedona_spatial_join_count_by_key","text":"spatial_rdd Spatial RDD containing geometries queried. query_window_rdd Spatial RDD containing query window(s). join_type Type join query (must either \"contain\" \"intersect\"). join_type \"contain\", geometry spatial_rdd match geometry query_window_rdd former fully contained latter. join_type \"intersect\", geometry spatial_rdd match geometry query_window_rdd former intersects latter. partitioner Spatial partitioning apply spatial_rdd query_window_rdd facilitate join query. Can either grid type (currently \"quadtree\" \"kdbtree\" supported) custom spatial partitioner object. partitioner NULL, assume spatial partitioner applied spatial_rdd query_window_rdd already skip partitioning step. index_type Controls spatial_rdd query_window_rdd indexed (unless indexed already). \"NONE\", index constructed matching geometries identified doubly nested- loop iterating possible pairs elements spatial_rdd query_window_rdd, inefficient large data sets.","code":""},{"path":"/reference/sedona_spatial_join_count_by_key.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Perform a spatial count-by-key operation based on two Sedona spatial RDDs. — sedona_spatial_join_count_by_key","text":"spatial RDD containing join-count--key results.","code":""},{"path":[]},{"path":"/reference/sedona_spatial_join_count_by_key.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Perform a spatial count-by-key operation based on two Sedona spatial RDDs. — sedona_spatial_join_count_by_key","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   input_location <- \"/dev/null\" # replace it with the path to your input file   rdd <- sedona_read_dsv_to_typed_rdd(     sc,     location = input_location,     delimiter = \",\",     type = \"point\",     first_spatial_col_index = 1L   )   query_rdd_input_location <- \"/dev/null\" # replace it with the path to your input file   query_rdd <- sedona_read_shapefile_to_typed_rdd(     sc,     location = query_rdd_input_location,     type = \"polygon\"   )   join_result_rdd <- sedona_spatial_join_count_by_key(     rdd,     query_rdd,     join_type = \"intersect\",     partitioner = \"quadtree\"   ) }"},{"path":"/reference/sedona_spatial_rdd_aggregation_routine.html","id":null,"dir":"Reference","previous_headings":"","what":"Spatial RDD aggregation routine — sedona_spatial_rdd_aggregation_routine","title":"Spatial RDD aggregation routine — sedona_spatial_rdd_aggregation_routine","text":"Function extracting aggregate statistics Sedona spatial RDD.","code":""},{"path":"/reference/sedona_spatial_rdd_aggregation_routine.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Spatial RDD aggregation routine — sedona_spatial_rdd_aggregation_routine","text":"x Sedona spatial RDD.","code":""},{"path":"/reference/sedona_spatial_rdd_data_source.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a SpatialRDD from an external data source. — sedona_spatial_rdd_data_source","title":"Create a SpatialRDD from an external data source. — sedona_spatial_rdd_data_source","text":"Import spatial object external data source Sedona SpatialRDD.","code":""},{"path":"/reference/sedona_spatial_rdd_data_source.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a SpatialRDD from an external data source. — sedona_spatial_rdd_data_source","text":"sc spark_connection. location Location data source. type Type SpatialRDD (must one \"point\", \"polygon\", \"linestring\". has_non_spatial_attrs Whether input contains non-spatial attributes. storage_level Storage level RDD (default: MEMORY_ONLY). repartition minimum number partitions resulting RDD (default: 1).","code":""},{"path":"/reference/sedona_visualization_routines.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualization routine for Sedona spatial RDD. — sedona_visualization_routines","title":"Visualization routine for Sedona spatial RDD. — sedona_visualization_routines","text":"Generate visual representation geometrical object(s) within Sedona spatial RDD.","code":""},{"path":"/reference/sedona_visualization_routines.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualization routine for Sedona spatial RDD. — sedona_visualization_routines","text":"rdd Sedona spatial RDD. resolution_x Resolution x-axis. resolution_y Resolution y-axis. output_location Location output image. desired path image file excluding extension file name. output_format File format output image. Currently \"png\", \"gif\", \"svg\" formats supported (default: \"png\"). boundary render data within given rectangular boundary. boundary parameter can set either numeric vector c(min_x, max_y, min_y, max_y) values, bounding box object e.g., new_bounding_box(sc, min_x, max_y, min_y, max_y), NULL (default). boundary NULL, minimum bounding box input spatial RDD computed used boundary rendering. color_of_variation color channel vary depending values data points. Must one \"red\", \"green\", \"blue\". Default: red. base_color Color data point value 0. Must numeric vector length 3 specifying values red, green, blue channels. Default: c(0, 0, 0). shade Whether data point larger magnitude displayed darker color. Default: TRUE. overlay viz_op object containing raster image displayed top resulting image. browse Whether open rendered image browser (default: interactive()).","code":""},{"path":"/reference/sedona_write_wkb.html","id":null,"dir":"Reference","previous_headings":"","what":"Write SpatialRDD into a file. — sedona_write_wkb","title":"Write SpatialRDD into a file. — sedona_write_wkb","text":"Export serialized data Sedona SpatialRDD file. sedona_write_wkb: sedona_write_wkt: sedona_write_geojson:","code":""},{"path":"/reference/sedona_write_wkb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write SpatialRDD into a file. — sedona_write_wkb","text":"","code":"sedona_write_wkb(x, output_location)  sedona_write_wkt(x, output_location)  sedona_write_geojson(x, output_location)"},{"path":"/reference/sedona_write_wkb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write SpatialRDD into a file. — sedona_write_wkb","text":"x SpatialRDD object. output_location Location output file.","code":""},{"path":"/reference/sedona_write_wkb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Write SpatialRDD into a file. — sedona_write_wkb","text":"return value.","code":""},{"path":[]},{"path":"/reference/sedona_write_wkb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write SpatialRDD into a file. — sedona_write_wkb","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   input_location <- \"/dev/null\" # replace it with the path to your input file   rdd <- sedona_read_wkb(     sc,     location = input_location,     wkb_col_idx = 0L   )   sedona_write_wkb(rdd, \"/tmp/wkb_output.tsv\") }"},{"path":"/reference/spark_read_shapefile.html","id":null,"dir":"Reference","previous_headings":"","what":"Read geospatial data into a Spark DataFrame. — spark_read_shapefile","title":"Read geospatial data into a Spark DataFrame. — spark_read_shapefile","text":"functions deprecated removed future release. Sedona implementing readers spark DataFrame sources, can use spark_read_source right sources (\"shapefile\", \"geojson\", \"geoparquet\") read geospatial data. Functions read geospatial data variety formats Spark DataFrames. spark_read_shapefile: shapefile spark_read_geojson: geojson file spark_read_geoparquet: geoparquet file","code":""},{"path":"/reference/spark_read_shapefile.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read geospatial data into a Spark DataFrame. — spark_read_shapefile","text":"","code":"spark_read_shapefile(sc, name = NULL, path = name, options = list(), ...)  spark_read_geojson(   sc,   name = NULL,   path = name,   options = list(),   repartition = 0,   memory = TRUE,   overwrite = TRUE )  spark_read_geoparquet(   sc,   name = NULL,   path = name,   options = list(),   repartition = 0,   memory = TRUE,   overwrite = TRUE )"},{"path":"/reference/spark_read_shapefile.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read geospatial data into a Spark DataFrame. — spark_read_shapefile","text":"sc spark_connection. name name assign newly generated table. path path file. Needs accessible cluster. Supports \"hdfs://\", \"s3a://\" \"file://\" protocols. options list strings additional options. See https://spark.apache.org/docs/latest/sql-programming-guide.html#configuration. ... Optional arguments; currently unused. repartition number partitions used distribute generated table. Use 0 (default) avoid partitioning. memory Boolean; data loaded eagerly memory? (, table cached?) overwrite Boolean; overwrite table given name already exists?","code":""},{"path":"/reference/spark_read_shapefile.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read geospatial data into a Spark DataFrame. — spark_read_shapefile","text":"tbl","code":""},{"path":[]},{"path":"/reference/spark_read_shapefile.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read geospatial data into a Spark DataFrame. — spark_read_shapefile","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   input_location <- \"/dev/null\" # replace it with the path to your input file   rdd <- spark_read_shapefile(sc, location = input_location) }"},{"path":"/reference/spark_write_geojson.html","id":null,"dir":"Reference","previous_headings":"","what":"Write geospatial data from a Spark DataFrame. — spark_write_geojson","title":"Write geospatial data from a Spark DataFrame. — spark_write_geojson","text":"functions deprecated removed future release. Sedona implementing writers spark DataFrame sources, can use spark_write_source right sources (\"shapefile\", \"geojson\", \"geoparquet\") write geospatial data. Functions write geospatial data variety formats Spark DataFrames. spark_write_geojson: GeoJSON spark_write_geoparquet: GeoParquet spark_write_raster: raster tiles using RS output functions (RS_AsXXX)","code":""},{"path":"/reference/spark_write_geojson.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Write geospatial data from a Spark DataFrame. — spark_write_geojson","text":"","code":"spark_write_geojson(   x,   path,   mode = NULL,   options = list(),   partition_by = NULL,   ... )  spark_write_geoparquet(   x,   path,   mode = NULL,   options = list(),   partition_by = NULL,   ... )  spark_write_raster(   x,   path,   mode = NULL,   options = list(),   partition_by = NULL,   ... )"},{"path":"/reference/spark_write_geojson.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Write geospatial data from a Spark DataFrame. — spark_write_geojson","text":"x Spark DataFrame dplyr operation path path file. Needs accessible cluster. Supports \"hdfs://\", \"s3a://\" \"file://\" protocols. mode character element. Specifies behavior data   table already exists. Supported values include: 'error', 'append', 'overwrite'   ignore. Notice 'overwrite' also change column structure. details see also https://spark.apache.org/docs/latest/sql-programming-guide.html#save-modes   version Spark. options list strings additional options. partition_by character vector. Partitions output given columns file system. ... Optional arguments; currently unused.","code":""},{"path":[]},{"path":"/reference/spark_write_geojson.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Write geospatial data from a Spark DataFrame. — spark_write_geojson","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   tbl <- dplyr::tbl(     sc,     dplyr::sql(\"SELECT ST_GeomFromText('POINT(-71.064544 42.28787)') AS `pt`\")   )   spark_write_geojson(     tbl %>% dplyr::mutate(id = 1),     output_location = \"/tmp/pts.geojson\"   ) }"},{"path":"/reference/spatial_join_op.html","id":null,"dir":"Reference","previous_headings":"","what":"Spatial join operator — spatial_join_op","title":"Spatial join operator — spatial_join_op","text":"R interface Sedona spatial join operator","code":""},{"path":"/reference/spatial_join_op.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Spatial join operator — spatial_join_op","text":"spatial_rdd Spatial RDD containing geometries queried. query_window_rdd Spatial RDD containing query window(s). join_type Type join query (must either \"contain\" \"intersect\"). join_type \"contain\", geometry spatial_rdd match geometry query_window_rdd former fully contained latter. join_type \"intersect\", geometry spatial_rdd match geometry query_window_rdd former intersects latter. partitioner Spatial partitioning apply spatial_rdd query_window_rdd facilitate join query. Can either grid type (currently \"quadtree\" \"kdbtree\" supported) custom spatial partitioner object. partitioner NULL, assume spatial partitioner applied spatial_rdd query_window_rdd already skip partitioning step. index_type Controls spatial_rdd query_window_rdd indexed (unless indexed already). \"NONE\", index constructed matching geometries identified doubly nested- loop iterating possible pairs elements spatial_rdd query_window_rdd, inefficient large data sets.","code":""},{"path":"/reference/spatial_query.html","id":null,"dir":"Reference","previous_headings":"","what":"Execute a spatial query — spatial_query","title":"Execute a spatial query — spatial_query","text":"Given spatial RDD, run spatial query parameterized spatial object x.","code":""},{"path":"/reference/spatial_query.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Execute a spatial query — spatial_query","text":"rdd Sedona spatial RDD. x query object. index_type Index use facilitate KNN query. NULL, build additional spatial index top x. Supported index types \"quadtree\" \"rtree\". result_type Type result return. \"rdd\" (default), k nearest objects returned Sedona spatial RDD. \"sdf\", Spark dataframe containing k nearest objects returned. \"raw\", list k nearest objects returned. element within list JVM object type org.locationtech.jts.geom.Geometry.","code":""},{"path":"/reference/to_spatial_rdd.html","id":null,"dir":"Reference","previous_headings":"","what":"Export a Spark SQL query with a spatial column into a Sedona spatial RDD. — to_spatial_rdd","title":"Export a Spark SQL query with a spatial column into a Sedona spatial RDD. — to_spatial_rdd","text":"Given Spark dataframe object dplyr expression encapsulating Spark SQL query, build Sedona spatial RDD encapsulate query data source. input contain exactly one spatial column non-spatial columns treated custom user-defined attributes resulting spatial RDD.","code":""},{"path":"/reference/to_spatial_rdd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Export a Spark SQL query with a spatial column into a Sedona spatial RDD. — to_spatial_rdd","text":"","code":"to_spatial_rdd(x, spatial_col)"},{"path":"/reference/to_spatial_rdd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Export a Spark SQL query with a spatial column into a Sedona spatial RDD. — to_spatial_rdd","text":"x Spark dataframe object sparklyr dplyr expression representing Spark SQL query. spatial_col name spatial column.","code":""},{"path":"/reference/to_spatial_rdd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Export a Spark SQL query with a spatial column into a Sedona spatial RDD. — to_spatial_rdd","text":"SpatialRDD encapsulating query.","code":""},{"path":"/reference/to_spatial_rdd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Export a Spark SQL query with a spatial column into a Sedona spatial RDD. — to_spatial_rdd","text":"","code":"library(sparklyr) library(apache.sedona)  sc <- spark_connect(master = \"spark://HOST:PORT\")  if (!inherits(sc, \"test_connection\")) {   tbl <- dplyr::tbl(     sc,     dplyr::sql(\"SELECT ST_GeomFromText('POINT(-71.064544 42.28787)') AS `pt`\")   )   rdd <- to_spatial_rdd(tbl, \"pt\") }"}]
